{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XFm2TblUV1Pu"
      },
      "outputs": [],
      "source": [
        "# @title Vid2densepose\n",
        "from IPython.display import clear_output, display, HTML\n",
        "\n",
        "%cd /content\n",
        "!wget https://huggingface.co/camenduru/densepose/raw/main/Base-DensePose-RCNN-FPN.yaml -O /content/Base-DensePose-RCNN-FPN.yaml\n",
        "!wget https://huggingface.co/camenduru/densepose/raw/main/densepose_rcnn_R_50_FPN_s1x.yaml -O /content/densepose_rcnn_R_50_FPN_s1x.yaml\n",
        "!pip install -q gradio\n",
        "!pip install -q https://huggingface.co/camenduru/densepose/resolve/main/detectron2-0.6-cp310-cp310-linux_x86_64.whl?download=true\n",
        "!pip install -q https://huggingface.co/camenduru/densepose/resolve/main/detectron2_densepose-0.6-py3-none-any.whl?download=true\n",
        "\n",
        "# https://github.com/Flode-Labs/vid2densepose/blob/main/app.py modified\n",
        "import gradio as gr\n",
        "from detectron2.config import get_cfg\n",
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from densepose import add_densepose_config\n",
        "from densepose.vis.extractor import DensePoseResultExtractor\n",
        "from densepose.vis.densepose_results import DensePoseResultsFineSegmentationVisualizer as Visualizer\n",
        "import tempfile\n",
        "import shutil\n",
        "\n",
        "def process_video(input_video_path):\n",
        "    output_video_path = tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False).name\n",
        "    cfg = get_cfg()\n",
        "    add_densepose_config(cfg)\n",
        "    cfg.merge_from_file(\"/content/densepose_rcnn_R_50_FPN_s1x.yaml\")\n",
        "    predictor = DefaultPredictor(cfg)\n",
        "    cap = cv2.VideoCapture(input_video_path)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        with torch.no_grad():\n",
        "            outputs = predictor(frame)['instances']\n",
        "        results = DensePoseResultExtractor()(outputs)\n",
        "        cmap = cv2.COLORMAP_VIRIDIS\n",
        "        arr = cv2.applyColorMap(np.zeros((height, width), dtype=np.uint8), cmap)\n",
        "        out_frame = Visualizer(alpha=1, cmap=cmap).visualize(arr, results)\n",
        "        out.write(out_frame)\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    return output_video_path\n",
        "iface = gr.Interface(\n",
        "    fn=process_video,\n",
        "    inputs=gr.Video(label=\"Input Video\"),\n",
        "    outputs=gr.Video(label=\"Output DensePose Video\"),\n",
        "    title=\"Video 2 DensePose\"\n",
        ")\n",
        "clear_output()\n",
        "iface.launch(share=True, inline=False, debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2XMt8QrV4aH"
      },
      "outputs": [],
      "source": [
        "iface.launch(share=True, inline=False, debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Yx5KgaA4V6F2"
      },
      "outputs": [],
      "source": [
        "# @title MagicAnimat\n",
        "from IPython.display import clear_output, display, HTML\n",
        "\n",
        "%cd /content\n",
        "!git clone https://github.com/Van-wise/magicanimate-colab MagicAnimate-hf\n",
        "!pip install typing-extensions==4.5.0\n",
        "!pip install -q diffusers==0.21.4 transformers==4.32.0 accelerate==0.22.0 omegaconf==2.3.0 einops==0.6.1 av gradio\n",
        "!pip install -q https://download.pytorch.org/whl/cu118/xformers-0.0.22.post4%2Bcu118-cp310-cp310-manylinux2014_x86_64.whl\n",
        "\n",
        "!apt -y install -qq aria2\n",
        "SDVAE_Url = \"https://huggingface.co/stabilityai/sd-vae-ft-mse/resolve/main\"\n",
        "SDVAE_Dir = \"/content/MagicAnimate-hf/sd-vae-ft-mse\"\n",
        "MA_Url = \"https://huggingface.co/zcxu-eric/MagicAnimate/resolve/main\"\n",
        "MA_Dir = \"/content/MagicAnimate-hf/MagicAnimate\"\n",
        "SD15_Url = \"https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main\"\n",
        "SD15_Dir = \"/content/MagicAnimate-hf/stable-diffusion-v1-5\"\n",
        "\n",
        "import subprocess\n",
        "from concurrent import futures\n",
        "\n",
        "def download_file(file_dLlink, save_dir, file_name):\n",
        "    try:\n",
        "        #subprocess.run(['aria2c', '--console-log-level=error', '-q', '-c', '-x', '16', '-s', '16', '-k', '1M', file_dLlink, '-d', save_dir, '-o', file_name], check=True)\n",
        "        !aria2c --console-log-level=error -q -c -x 16 -s 16 -k 1M {file_dLlink} -d {save_dir} -o {file_name}\n",
        "        print(f\"File {save_dir}/{file_name} downloaded successfully!\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Error downloading file {file_name}: {e}\")\n",
        "\n",
        "# 定义要下载的文件列表\n",
        "file_list = [\n",
        "    (SD15_Url + \"/v1-5-pruned-emaonly.safetensors\", SD15_Dir, \"v1-5-pruned-emaonly.safetensors\"),\n",
        "    (SDVAE_Url + \"/diffusion_pytorch_model.bin\", SDVAE_Dir, \"diffusion_pytorch_model.bin\"),\n",
        "    (SDVAE_Url + \"/diffusion_pytorch_model.safetensors\", SDVAE_Dir, \"diffusion_pytorch_model.safetensors\"),\n",
        "    (SDVAE_Url + \"/config.json\", SDVAE_Dir, \"config.json\"),\n",
        "    (MA_Url + \"/appearance_encoder/diffusion_pytorch_model.safetensors\", MA_Dir + \"/appearance_encoder\", \"diffusion_pytorch_model.safetensors\"),\n",
        "    (MA_Url + \"/appearance_encoder/config.json\", MA_Dir + \"/appearance_encoder\", \"config.json\"),\n",
        "    (MA_Url + \"/densepose_controlnet/diffusion_pytorch_model.safetensors\", MA_Dir + \"/densepose_controlnet\", \"diffusion_pytorch_model.safetensors\"),\n",
        "    (MA_Url + \"/densepose_controlnet/config.json\", MA_Dir + \"/densepose_controlnet\", \"config.json\"),\n",
        "    (MA_Url + \"/temporal_attention/temporal_attention.ckpt\", MA_Dir + \"/temporal_attention\", \"temporal_attention.ckpt\"),\n",
        "    (SD15_Url + \"/feature_extractor/preprocessor_config.json\", SD15_Dir + \"/feature_extractor\", \"preprocessor_config.json\"),\n",
        "    (SD15_Url + \"/safety_checker/pytorch_model.bin\", SD15_Dir + \"/safety_checker\", \"pytorch_model.bin\"),\n",
        "    (SD15_Url + \"/safety_checker/config.json\", SD15_Dir + \"/safety_checker\", \"config.json\"),\n",
        "    (SD15_Url + \"/scheduler/scheduler_config.json\", SD15_Dir + \"/scheduler\", \"scheduler_config.json\"),\n",
        "    (SD15_Url + \"/text_encoder/pytorch_model.bin\", SD15_Dir + \"/text_encoder\", \"pytorch_model.bin\"),\n",
        "    (SD15_Url + \"/text_encoder/config.json\", SD15_Dir + \"/text_encoder\", \"config.json\"),\n",
        "    (SD15_Url + \"/tokenizer/merges.txt\", SD15_Dir + \"/tokenizer\", \"merges.txt\"),\n",
        "    (SD15_Url + \"/tokenizer/special_tokens_map.json\", SD15_Dir + \"/tokenizer\", \"special_tokens_map.json\"),\n",
        "    (SD15_Url + \"/tokenizer/tokenizer_config.json\", SD15_Dir + \"/tokenizer\", \"tokenizer_config.json\"),\n",
        "    (SD15_Url + \"/tokenizer/vocab.json\", SD15_Dir + \"/tokenizer\", \"vocab.json\"),\n",
        "    (SD15_Url + \"/unet/diffusion_pytorch_model.bin\", SD15_Dir + \"/unet\", \"diffusion_pytorch_model.bin\"),\n",
        "    (SD15_Url + \"/unet/config.json\", SD15_Dir + \"/unet\", \"config.json\"),\n",
        "    (SD15_Url + \"/vae/diffusion_pytorch_model.bin\", SD15_Dir + \"/vae\", \"diffusion_pytorch_model.bin\"),\n",
        "    (SD15_Url + \"/vae/config.json\", SD15_Dir + \"/vae\", \"config.json\"),\n",
        "    (SD15_Url + \"/model_index.json\", SD15_Dir, \"model_index.json\"),\n",
        "    (SD15_Url + \"/v1-inference.yaml\", SD15_Dir, \"v1-inference.yaml\")\n",
        "]\n",
        "\n",
        "# 创建线程池并下载文件\n",
        "with futures.ThreadPoolExecutor() as executor:\n",
        "    download_tasks = [executor.submit(download_file, file_dLlink, save_dir, file_name) for file_dLlink, save_dir, file_name in file_list]\n",
        "\n",
        "    # 等待所有下载任务完成\n",
        "    for future in futures.as_completed(download_tasks):\n",
        "        try:\n",
        "            future.result()\n",
        "        except Exception as e:\n",
        "            print(f\"Error downloading file: {e}\")\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "6z6pI22EWFMd"
      },
      "outputs": [],
      "source": [
        "#@markdown #####<font color=\"#2c9678\">SD1.5模型下载链接:\n",
        "SD15_link = \"https://civitai.com/api/download/models/11745\" # @param {type:\"string\"}\n",
        "!rm -rf {SD15_Dir}/v1-5-pruned-emaonly.safetensors\n",
        "!aria2c --console-log-level=error -q -c -x 16 -s 16 -k 1M {SD15_link} -d {SD15_Dir}/v1-5-pruned.safetensors -o v1-5-pruned.safetensors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-_4MS3FWF43"
      },
      "outputs": [],
      "source": [
        "%cd /content/MagicAnimate-hf\n",
        "!python app.py"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
